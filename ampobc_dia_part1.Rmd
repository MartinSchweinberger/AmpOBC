---
title: "Analyzing change in the British English Adjective Amplifier System based on the Old Baily Corpus (Part 1)"
author: "Martin Schweinberger"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---


This document reports the analysis of the use of adjective amplifiers in British English based on the [Old Bailey Corpus (Version 2.0)](https://fedora.clarin-d.uni-saarland.de/oldbailey/).

# Introduction

We will now begin with the analysis. In a first step, the session is prepared by setting options and activating packages.

```{r ampobc_1_01, message=F, warning=F}
# load packages
library(tidyverse)  # data processing
library(tidyr)      # data processing
library(knitr)      # table vis
library(kableExtra) # table vis
library(DT)         # table vis
library(usethis)    # git
library(textreadr)  # reah xml
library(textdata)   # sentiment analysis
library(quanteda)   # concordancing
library(hunspell)   # spelling
library(udpipe)     # pos tagging
# set options
options(stringsAsFactors = F)
options(scipen = 999)
options(max.print=10000)
# specify paths
corpuspath <- "D:\\Uni\\Korpora\\Original\\OldBaileyCorpus\\OldBaileyCorpus2\\OldBaileyCorpus2\\OBC2"
# define corpus files
corpusfiles = list.files(path = corpuspath, pattern = "POS", all.files = T,
                         full.names = T, recursive = F, ignore.case = T, 
                         include.dirs = F)
# for testing purposes we only use the first 5 files
corpusfiles <- corpusfiles[1:5]
# inspect
head(corpusfiles)
```

# Data Processing

Load and process data

```{r ampobc_1_02}
# load and start processing corpus
obc <- sapply(corpusfiles, function(x) {
  x <- textreadr::read_xml(x)
  x <- paste0(x, collapse = " ")
  x <- stringr::str_remove_all(x, "\n")
  x <- stringr::str_squish(x)
  x <- stringr::str_replace_all(x, " ([:punct:])", "\\1")
} ) 
# inspect
str(obc)
```

## Extract meta information{-}

```{r ampobc_1_03, message=F, warning=F}
# extract file names
File <- names(obc)
File <- stringr::str_remove_all(File, ".*/")
File <- gsub(".xml", "", File)
# extract raw text
Text <- as.vector(unlist(obc))
# extract date
Date <- stringr::str_extract_all(File, "POS-[0-9]{4,4}") %>%
  stringr::str_remove_all("POS-")
# clean text
CleanText <- Text %>%
  stringr::str_remove_all(fixed("\\")) %>%
  stringr::str_remove_all("_[:graph:]") %>%
  tolower() %>%
  stringr::str_squish()
# extract wordcount
words <- stringr::str_count(CleanText, " ")+1
# create an id
docname <- paste0("text", 1:length(Text))
# combine elements into a data frame 
obcdf <- data.frame(docname, File, Date, Text, CleanText, words)
# inspect
nrow(obcdf)
```

Save data to disc

```{r ampobc_1_04, message=F, warning=F}
# save data
base::saveRDS(obcdf, file = here::here("data", "obcdf_raw.rda"))
# reload data
obcdf  <- base::readRDS(file = here::here("data", "obcdf_raw.rda"))
```


## Concordancing{-}

```{r ampobc_1_05, message=F, warning=F}
# generate kwic
concobc <- quanteda::kwic(obcdf$Text, 
                         pattern = "[:alnum:]{1,}_JJ[:alnum:]{0,3}", 
                         window = 15, 
                         valuetype = "regex") %>%
  as.data.frame() %>%
  dplyr::select(-pattern, -from, -to)
# inspect
head(concobc)
```




```{r ampobc_1_06, message=F, warning=F}
meta <- obcdf %>%
  dplyr::select(docname, File, Date, words)
# combine meta and kwic
ampobc <- dplyr::left_join(concobc, meta, by = "docname") %>%
  dplyr::mutate(id = 1:nrow(.))
# inspect
head(ampobc)
```

Visualize distribution of files against `Date`

```{r ampobc_1_07, message=F, warning=F}
ampobc %>%
  ggplot(aes(x = Date)) + 
  geom_histogram(stat="count")
```


Save data to disc

```{r ampobc_1_08, message=F, warning=F}
# save data
base::saveRDS(ampobc, file = here::here("data", "ampobc_raw.rda"))
# reload data
ampobc  <- base::readRDS(file = here::here("data", "ampobc_raw.rda"))
```



## Frequency{-}

```{r ampobc_1_09, message=F, warning=F}
# code freq of adj type by date category
ampobc <- ampobc %>%
  dplyr::mutate(adjective = tolower(keyword),
                adjective = str_remove_all(adjective, "_.*"),
                Datecat = Date %>%
                  as.numeric()) %>%
  dplyr::mutate(Datecat = dplyr::case_when(Datecat >= 1900 ~ "1900-1999",
                                           Datecat >= 1800 ~ "1800-1899",
                                           Datecat >= 1700 ~ "1700-1799",
                                           TRUE ~ "1600-1699")) %>%
  dplyr::group_by(Datecat, adjective) %>%
  dplyr::mutate(adjectiveN = n()) %>%
  dplyr::group_by(Datecat) %>%
  dplyr::mutate(adjectivesN = n()) %>%
  dplyr::mutate(frequency = round(adjectiveN/adjectivesN*1000, 5))
# inspect
head(ampobc)
```


Save data to disc

```{r ampobc_1_10, message=F, warning=F}
# save data
base::saveRDS(ampobc, file = here::here("data", "ampobc_semi.rda"))
# reload data
ampobc  <- base::readRDS(file = here::here("data", "ampobc_semi.rda"))
```



## Syntactic Function{-}

```{r ampobc_1_11, message=F, warning=F}
# determine function
Function1 <- ampobc$post %>%
  stringr::str_squish() %>%
  tolower() %>%
  stringr::str_replace_all(" .*", "") %>%
  stringr::str_replace_all(".*_n.*", "Attributive") %>%
  stringr::str_replace_all(fixed("/."), "PUNCT") %>%
  stringr::str_replace_all(".*PUNCT.*", "Attributive")
Function2 <-  ampobc$post %>%
  stringr::str_squish() %>%
  tolower() %>%
  stringr::str_replace(" ", "") %>%
  stringr::str_replace_all(" .*", "") %>%
  stringr::str_replace_all(".*_n.*", "Attributive") %>%
  stringr::str_replace_all(fixed("/."), "PUNCT") %>%
  stringr::str_replace_all(".*PUNCT.*", "Attributive")
functiontb <- cbind(Function1, Function2)
# inspect 
head(functiontb)
```

## Check Amplifiers{-}

not included: *quite*, *too*, and *well*.

```{r ampobc_1_12, message=F, warning=F}
# define amplifiers 
amplifiers <- c("absolutely", "actually", "aggressively", "amazingly", "appallingly", "awful", 
                "awfully", "badly", "bloody", "certainly", "clearly", "complete", "dead", "completely", 
                "considerably", "crazy", "decidedly", "definitely", "distinctly", "dreadfully", 
                "enormously", "entirely", "especially", "exactly", "exceedingly", "exceptionally", 
                "excruciatingly", "extraordinarily", "extremely", "fiercely", "firmly", "frightfully", 
                "fucking", "fully", "genuinely", "greatly", "grossly", "heavily", "highly", "hopelessly",
                "horrendously", "hugely", "immediately", "immensely", "incredibly", "infinitely", 
                "intensely", "irrevocably", "mad", "mega", "mighty", "most", "much", "obviously", 
                "openly", "overwhelmingly", "particularly", "perfectly", "plenty", "positively", 
                "precisely", "pretty", "profoundly", "purely", "real", "really", "remarkably", "seriously",
                "shocking", "significant", "significantly", "so", "specially", "specifically", "strikingly", 
                "strongly", "substantially", "super", "surely", "terribly", "terrifically", "total", 
                "totally", "traditionally", "true", "truly", "ultra", "utterly", "very", "viciously", 
                "wholly", "wicked", "wildly")
```


```{r ampobc_1_13, message=F, warning=F}
ampobc <- ampobc %>%
  dplyr::mutate(Function = dplyr::case_when(Function1 == "" | 
                                              Function1 == "Attributive" | 
                                              Function2 == "Attributive" ~ "Attributive",
                                            FALSE ~ "Predicative")) %>%
  # extract variant
  dplyr::mutate(Variant = tolower(pre),
                Variant = str_remove_all(Variant, ".* "),
                Variant = str_remove_all(Variant, "_.*"),
                Variant = ifelse(Variant %in% amplifiers, Variant, "Zero")) %>%
  # code amplification
  dplyr::mutate(Amplified = ifelse(Variant == "Zero", 0, 1))
# inspect
head(ampobc)
```


## Code Priming{-}

```{r ampobc_1_14, message=F, warning=F}
# code priming
prim1 <- c(rep(0, 1), ampobc$Variant[1:length(ampobc$Variant)-1])
prim2 <- c(rep(0, 2), ampobc$Variant[1:(length(ampobc$Variant)-2)])
prim3 <- c(rep(0, 3), ampobc$Variant[1:(length(ampobc$Variant)-3)])
primtb <- cbind(ampobc$Variant, prim1, prim2, prim3)
# inspect
head(primtb)
```


```{r ampobc_1_15, message=F, warning=F}
ampobc$Priming <- as.vector(unlist(apply(primtb, 1, function(x){
  x <- ifelse(x[1]== "Zero" , "NoPrime",
              ifelse(x[1] == x[2] | x[1] == x[3] | x[1] == x[4], "Prime", "NoPrime"))
})))
# define forms that require removal
sups <- c(".*most.*", ".*more.*") 
negs <- c(".*not.*", ".*never.*", ".*n't.*")
downtoners <- c(".*sort_.*", ".*kind_.*", ".* bit_.*", ".*somewhat.*", ".*fairly.*", 
                ".*rather.*", ".*reasonably.*", ".*slightly.*", ".*comparatively.*", ".*semi.*", 
                ".*relatively.*", ".*little.*", ".*somehow.*", ".*almost.*", ".*partly.*", 
                ".*hardly.*", ".* less.*", ".*barely.*", ".* just_.*")
specialforms <- c(".* too.*", ".*quite.*")
PostContextdowntoners <- c(".*enough.*")
nonpropadj <- c("only", "much", "many", "cheaper", "cheaperr", "bests", "larger",
                "bst", "better", "bigger")
# check length of dataset
str(ampobc); head(ampobc); nrow(ampobc)
```

## Remove negated forms et al.{-}

```{r ampobc_1_16, message=F, warning=F}
# find items to be removed
supsidx <- unique(grep(paste(sups,collapse="|"), ampobc$pre, value=F))
negsidx <- unique(grep(paste(negs,collapse="|"), ampobc$pre, value=F))
downtonersidx <- unique(grep(paste(downtoners,collapse="|"), ampobc$pre, value=F))
specialformsidx <- unique(grep(paste(specialforms,collapse="|"), ampobc$pre, value=F))
PostContextdowntonersidx <- unique(grep(paste(PostContextdowntoners,collapse="|"), ampobc$PostContext, value=F))
nonpropadjidx <- unique(grep(paste(nonpropadj,collapse="|"), ampobc$Adjective, value=F))
# combine indices
idxs <- unique(c(supsidx, negsidx, downtonersidx, specialformsidx, PostContextdowntonersidx, nonpropadjidx))
# remove forms that require removal
ampobc <- ampobc[-idxs,]
# remove empty values
ampobc <- ampobc[!ampobc$Variant == "", ]
# inspect
head(ampobc)
```


Save data to disc

```{r ampobc_1_17, message=F, warning=F}
# save data
base::saveRDS(ampobc, file = here::here("data", "ampobc_woneg.rda"))
# reload data
ampobc  <- base::readRDS(file = here::here("data", "ampobc_woneg.rda"))
```


## Remove misspelled forms {-}

```{r ampobc_1_19, message=F, warning=F, eval = F}
# inspect adjectives
names(table(ampobc$adjective))[1:10]
```

Remove words not in dictionary or words that consist only of 1 or 2 characters

```{r ampobc_1_20, message=F, warning=F}
nrow(ampobc)
# correct spelling
ampobc <- ampobc %>%
  dplyr::filter(hunspell_check(adjective)) %>%
  dplyr::filter(nchar(adjective) > 2)
# inspect
head(ampobc); nrow(ampobc)
```



## Remove strange forms{-}

```{r ampobc_1_21, message=F, warning=F}
# inspect adjectives
names(table(ampobc$adjective))[1:10]
```

Remove mistagged items

```{r ampobc_1_22, message=F, warning=F}
#model <- udpipe_download_model(language = "english")
udmodel_english <- udpipe_load_model(file = here::here("english-ewt-ud-2.5-191206.udpipe"))
udpipe_adjectives <- udpipe_annotate(udmodel_english, ampobc$adjective) %>%
  data.frame() %>%
  dplyr::filter(xpos == "JJ") %>%
  dplyr::pull(sentence)
# inspect
head(udpipe_adjectives)
```

```{r ampobc_1_23, message=F, warning=F}
nrow(ampobc)
ampobc <-ampobc %>%
  dplyr::filter(adjective %in% udpipe_adjectives)
# inspect
nrow(ampobc)
```

Remove adjectives that were never amplified


```{r ampobc_1_24, message=F, warning=F}
amp_adjs <- ampobc %>%
  dplyr::filter(Amplified == 1) %>%
  dplyr::pull(adjective) %>%
  table() %>%
  names()
# inspect
head(amp_adjs)
```


```{r ampobc_1_25, message=F, warning=F}
nrow(ampobc)
ampobc <- ampobc %>%
  dplyr::filter(adjective %in% amp_adjs)
nrow(ampobc)
```

Save data to disc

```{r ampobc_1_26, message=F, warning=F}
# save data
base::saveRDS(ampobc, file = here::here("data", "ampobc_clean.rda"))
# reload data
ampobc  <- base::readRDS(file = here::here("data", "ampobc_clean.rda"))
```

## Gradability{-}

```{r ampobc_1_27, message=F, warning=F}
# code gradability
# load Gradability data (derived from COCA)
gradability <- read.delim(here::here("data", "Gradability.txt"), sep = "\t", header = T, quote = "", skipNul = T)
ampobc$Gradability <- ifelse(ampobc$adjective %in% gradability$Adjective, gradability$Beta, 1)
# inspect data
nrow(ampobc); head(ampobc)
```

## Semantic Classification{-}

Add semantic types [@tagliamonte2008intensifiers, @dixon1977adjectives]

* dimension = semdim (e.g. big, large, little, small, long, short, wide, narrow, thick)

* difficulty = semdif (e.g. difficult, simple)

* physical property = (e.g. hard, soft, heavy, light, rough, smooth, hot, sweet)

* color = semcol (e.g. black, white, red)

* human propensity: semhup (e.g. jealous, happy, kind, clever, generous, gay, rude)

* age = semage (e.g. new, young, old) 

* value (e.g. good, bad, proper, perfect, excellent, delicious, poor), 

* speed Speed (fast, quick, slow)

* position (e.g. right, left, near, far)

* other

```{r ampobc_1_28, message=F, warning=F}
# load data
code1 <- read.delim(here::here("data", "semcodecg1.txt"), sep = "\t", header = T, skipNul = T)
code2 <- read.delim(here::here("data", "semcodedjm1.txt"), sep = "\t", header = T, skipNul = T)
code3 <- read.delim(here::here("data", "semcodedl1.txt"), sep = "\t", header = T, skipNul = T)
code4 <- read.delim(here::here("data", "semcodedm1.txt"), sep = "\t", header = T, skipNul = T)
code5 <- read.delim(here::here("data", "semcodedma1.txt"), sep = "\t", header = T, skipNul = T)
code6 <- read.delim(here::here("data", "semcodedv1.txt"), sep = "\t", header = T, skipNul = T)
code7 <- read.delim(here::here("data", "semcodedjw1.txt"), sep = "\t", header = T, skipNul = T)
# order data sets
code1 <- code1[order(code1$Id),]
code2 <- code2[order(code2$Id),]
code3 <- code3[order(code3$Id),]
code4 <- code4[order(code4$Id),]
code5 <- code5[order(code5$Id),]
code6 <- code6[order(code6$Id),]
code7 <- code6[order(code7$Id),]
# repair adjectives in code1
code3$Adjective <- code1$Adjective
# combine tables
semcode <- rbind(code1, code2, code3, code4, code5, code6, code7)
# convert coding into numeric values
semcode[,3:12] <- t(apply(semcode[,3:12], 1, function(x) {
  x <- ifelse(x == "" | x == "?"| is.na(x) == T, 0, 1)}))
# convert into data frame
semcode <- as.data.frame(semcode)
# add column names
colnames(semcode)[3:12] <- c("Dimension", "Difficulty", "PhysicalProperty", "Color",
                             "HumanPropensity", "Age", "Value", "Speed", "Position", 
                             "Other")
```


```{r ampobc_1_29, message=F, warning=F}
# load package
library(dplyr)
AdjectiveSemantics <- semcode %>%
  dplyr::group_by(Adjective) %>%
  na.omit() %>%
  dplyr::summarize(Dimension = sum(Dimension), 
                   Difficulty = sum(Difficulty),
                   PhysicalProperty = sum(PhysicalProperty), 
                   Color = sum(Color),
                   HumanPropensity = sum(HumanPropensity), 
                   Age = sum(Age),
                   Value = sum(Value), 
                   Speed = sum(Speed),
                   Position = sum(Position), 
                   Other = sum(Other)) %>%
  dplyr::mutate(OverallScore = rowSums(.[,2:11])) %>%
  dplyr::mutate(Maximum = do.call(pmax, (.[,2:11]))) %>%
  dplyr::mutate(Certainty = Maximum/OverallScore*100)
AdjectiveSemantics <- AdjectiveSemantics %>%
  dplyr::mutate(Category = colnames(AdjectiveSemantics[2:11])[apply(AdjectiveSemantics[2:11],1,which.max)])
# inspect interrater reliability
summary(AdjectiveSemantics$Certainty)
```

```{r ampobc_1_30, message=F, warning=F}
Age <- AdjectiveSemantics %>%
  dplyr::filter(Age != 0) %>%
  dplyr::pull(Adjective)
Color <- AdjectiveSemantics %>%
  dplyr::filter(Color != 0) %>%
  dplyr::pull(Adjective)
Difficulty <- AdjectiveSemantics %>%
  dplyr::filter(Difficulty != 0) %>%
  dplyr::pull(Adjective)
Dimension <- AdjectiveSemantics %>%
  dplyr::filter(Dimension != 0) %>%
  dplyr::pull(Adjective)
HumanPropensity <- AdjectiveSemantics %>%
  dplyr::filter(HumanPropensity != 0) %>%
  dplyr::pull(Adjective)
PhysicalProperty <- AdjectiveSemantics %>%
  dplyr::filter(PhysicalProperty != 0) %>%
  dplyr::pull(Adjective)
Position <- AdjectiveSemantics %>%
  dplyr::filter(Position != 0) %>%
  dplyr::pull(Adjective)
Speed <- AdjectiveSemantics %>%
  dplyr::filter(Speed != 0) %>%
  dplyr::pull(Adjective)
Value <- AdjectiveSemantics %>%
  dplyr::filter(Value != 0) %>%
  dplyr::pull(Adjective)
# add semantic category to data
ampobc <- ampobc %>%
  dplyr::mutate(SemanticCategory = dplyr::case_when(adjective %in% Age ~ "Age",
                                                    adjective %in% Color ~ "Color",
                                                    adjective %in% Difficulty ~ "Difficulty",
                                                    adjective %in% Dimension ~ "Dimension",
                                                    adjective %in% HumanPropensity ~ "HumanPropensity",
                                                    adjective %in% PhysicalProperty ~ "PhysicalProperty",
                                                    adjective %in% Position ~ "Position",
                                                    adjective %in% Speed ~ "Speed",
                                                    adjective %in% Value ~ "Value", 
                                                    TRUE ~ "Other"))
# table sem class of tokens
table(ampobc$SemanticCategory)
```


## Sentiment Analysis{-}

```{r ampobc_1_31, message=F, warning=F}
# positive adjectives
pos_adj <- tidytext::get_sentiments("nrc") %>%
  dplyr::filter(sentiment == "positive") %>%
  dplyr::pull(word)
# negative adjectives
neg_adj <- tidytext::get_sentiments("nrc") %>%
  dplyr::filter(sentiment == "negative") %>%
  dplyr::pull(word)
# annotate emotionality
ampobc <- ampobc %>%
  dplyr::mutate(Emotionality = dplyr::case_when(adjective %in% pos_adj ~ "positive",
                                                adjective %in% neg_adj ~ "negative",
                                                TRUE ~ "neutral")) %>%
  dplyr::mutate(Emotionality = factor(Emotionality, levels = c("neutral", "negative", "positive")))
# inspect
head(ampobc)
```

## Correct errors{-}

```{r ampobc_1_32, message=F, warning=F}
ampobc %>%
  dplyr::filter(Variant == "so") %>%
  dplyr::group_by(Variant, Function) %>%
  dplyr::summarize(Frequency = n())
```


```{r ampobc_1_33, message=F, warning=F}
ampobc <- ampobc %>%
  dplyr::mutate(Function = ifelse(Variant == "so" & Function == "Attributive", "Predicative", Function))
```

```{r ampobc_1_34, message=F, warning=F}
ampobc %>%
  dplyr::filter(Variant == "so") %>%
  dplyr::group_by(Variant, Function) %>%
  dplyr::summarize(Frequency = n())
```

```{r ampobc_1_35, message=F, warning=F}
# inspect data
ampobc %>%
  head(10) %>%
  kable(caption = "First 10 rows of ampobc.") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                            full_width = F)
```


Save data to disc

```{r ampobc_1_36, message=F, warning=F}
# save data
base::saveRDS(ampobc, file = here::here("data", "ampobc_fullclean.rda"))
```




# Citation & Session Info {-}

Schweinberger, Martin. `r format(Sys.time(), '%Y')`. *Analyzing change in the British English Adjective Amplifier System based on the Old Baily Corpus (Part 1)*. Brisbane: The University of Queensland. url: https://slcladal.github.io/ampobc_dia_part1.html (Version `r format(Sys.time(), '%Y.%m.%d')`).

```
@manual{schweinberger`r format(Sys.time(), '%Y')`ampobc1,
  author = {Schweinberger, Martin},
  title = {Analyzing change in the British English Adjective Amplifier System based on the Old Baily Corpus (Part 1)},
  note = {https://slcladal.github.io/ampobc_dia_part1.html},
  year = {`r format(Sys.time(), '%Y')`},
  organization = {The University of Queensland, School of Languages and Cultures},
  address = {Brisbane},
  edition = {`r format(Sys.time(), '%Y.%m.%d')`}
}
```

```{r ampobc_1_40, message=F, warning=F}
sessionInfo()
```


***

[Back to top](#introduction)


***

# References {-}

